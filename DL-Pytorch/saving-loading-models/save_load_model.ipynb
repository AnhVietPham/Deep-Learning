{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "save-load-model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOENzOWFBb41o2Q3YEmhbsA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnhVietPham/Deep-Learning/blob/main/DL-Pytorch/saving-loading-models/save_load_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKOxT7U_TUvc",
        "outputId": "558690a2-057a-4664-f9a2-8146dfa8e991"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f64771c0af0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lvbdiQdTbdJ"
      },
      "source": [
        "class TheModelClass(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TheModelClass, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding=1, bias=False)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding=1, bias=False)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding=1, bias=False)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.fc1 = nn.Linear(3 * 3, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool3(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.softmax(F.relu(self.fc1(x)), dim=1)\n",
        "        return x\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpU03ZFlTiB9",
        "outputId": "d7c5be0b-8ac9-425f-8f29-aedd1088f708"
      },
      "source": [
        "x = torch.randn(1, 1, 28, 28)\n",
        "x"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-1.1258e+00, -1.1524e+00, -2.5058e-01, -4.3388e-01,  8.4871e-01,\n",
              "            6.9201e-01, -3.1601e-01, -2.1152e+00,  3.2227e-01, -1.2633e+00,\n",
              "            3.4998e-01,  3.0813e-01,  1.1984e-01,  1.2377e+00,  1.1168e+00,\n",
              "           -2.4728e-01, -1.3527e+00, -1.6959e+00,  5.6665e-01,  7.9351e-01,\n",
              "            5.9884e-01, -1.5551e+00, -3.4136e-01,  1.8530e+00,  7.5019e-01,\n",
              "           -5.8550e-01, -1.7340e-01,  1.8348e-01],\n",
              "          [ 1.3894e+00,  1.5863e+00,  9.4630e-01, -8.4368e-01, -6.1358e-01,\n",
              "            3.1593e-02, -4.9268e-01,  2.4841e-01,  4.3970e-01,  1.1241e-01,\n",
              "            6.4079e-01,  4.4116e-01, -1.0231e-01,  7.9244e-01, -2.8967e-01,\n",
              "            5.2507e-02,  5.2286e-01,  2.3022e+00, -1.4689e+00, -1.5867e+00,\n",
              "           -6.7309e-01,  8.7283e-01,  1.0554e+00,  1.7784e-01, -2.3034e-01,\n",
              "           -3.9175e-01,  5.4329e-01, -3.9516e-01],\n",
              "          [-4.4622e-01,  7.4402e-01,  1.5210e+00,  3.4105e+00, -1.5312e+00,\n",
              "           -1.2341e+00,  1.8197e+00, -5.5153e-01, -5.6925e-01,  9.1997e-01,\n",
              "            1.1108e+00,  1.2899e+00, -1.4782e+00,  2.5672e+00, -4.7312e-01,\n",
              "            3.3555e-01, -1.6293e+00, -5.4974e-01, -4.7983e-01, -4.9968e-01,\n",
              "           -1.0670e+00,  1.1149e+00, -1.4067e-01,  8.0575e-01, -9.3348e-02,\n",
              "            6.8705e-01, -8.3832e-01,  8.9182e-04],\n",
              "          [ 8.4189e-01, -4.0003e-01,  1.0395e+00,  3.5815e-01, -2.4600e-01,\n",
              "            2.3025e+00, -1.8817e+00, -4.9727e-02, -1.0450e+00, -9.5650e-01,\n",
              "            3.3532e-02,  7.1009e-01,  1.6459e+00, -1.3602e+00,  3.4457e-01,\n",
              "            5.1987e-01, -2.6133e+00, -1.6965e+00, -2.2824e-01,  2.7995e-01,\n",
              "            2.4693e-01,  7.6887e-02,  3.3801e-01,  4.5440e-01,  4.5694e-01,\n",
              "           -8.6537e-01,  7.8131e-01, -9.2679e-01],\n",
              "          [-2.1883e-01, -2.4351e+00, -7.2915e-02, -3.3986e-02,  9.6252e-01,\n",
              "            3.4917e-01, -9.2146e-01, -5.6195e-02, -6.2270e-01, -4.6372e-01,\n",
              "            1.9218e+00, -4.0255e-01,  1.2390e-01,  1.1648e+00,  9.2337e-01,\n",
              "            1.3873e+00, -8.8338e-01, -4.1891e-01, -8.0483e-01,  5.6561e-01,\n",
              "            6.1036e-01,  4.6688e-01,  1.9507e+00, -1.0631e+00, -7.7326e-02,\n",
              "            1.1640e-01, -5.9399e-01, -1.2439e+00],\n",
              "          [-1.0209e-01, -1.0335e+00, -3.1264e-01,  2.4579e-01, -2.5964e-01,\n",
              "            1.1834e-01,  2.4396e-01,  1.1646e+00,  2.8858e-01,  3.8660e-01,\n",
              "           -2.0106e-01, -1.1793e-01,  1.9220e-01, -7.7216e-01, -1.9003e+00,\n",
              "            1.3068e-01, -7.0429e-01,  3.1472e-01,  1.5739e-01,  3.8536e-01,\n",
              "            9.6715e-01, -9.9108e-01,  3.0161e-01, -1.0732e-01,  9.9846e-01,\n",
              "           -4.9871e-01,  7.6111e-01,  6.1830e-01],\n",
              "          [ 3.1405e-01,  2.1333e-01, -1.2005e-01,  3.6046e-01, -3.1403e-01,\n",
              "           -1.0787e+00,  2.4081e-01, -1.3962e+00, -6.6144e-02, -3.5836e-01,\n",
              "           -1.5616e+00, -3.5464e-01,  1.0811e+00,  1.3148e-01,  1.5735e+00,\n",
              "            7.8143e-01, -1.0787e+00, -7.2091e-01,  1.4708e+00,  2.7564e-01,\n",
              "            6.6678e-01, -9.9439e-01, -1.1894e+00, -1.1959e+00, -5.5963e-01,\n",
              "            5.3347e-01,  4.0689e-01,  3.9459e-01],\n",
              "          [ 1.7151e-01,  8.7604e-01, -2.8709e-01,  1.0216e+00, -7.4395e-02,\n",
              "           -1.0922e+00,  3.9203e-01,  5.9453e-01,  6.6227e-01, -1.2063e+00,\n",
              "            6.0744e-01, -5.4716e-01,  1.1711e+00,  9.7496e-02,  9.6337e-01,\n",
              "            8.4032e-01, -1.2537e+00,  9.8684e-01, -4.9466e-01, -1.2830e+00,\n",
              "            9.5522e-01,  1.2836e+00, -6.6586e-01,  5.6513e-01,  2.8770e-01,\n",
              "           -3.3375e-02, -1.0619e+00, -1.1443e-01],\n",
              "          [-3.4334e-01,  1.5713e+00,  1.9161e-01,  3.7994e-01, -1.4476e-01,\n",
              "            6.3762e-01, -2.8129e-01, -1.3299e+00, -1.4201e-01, -5.3415e-01,\n",
              "           -5.2338e-01,  8.6150e-01, -8.8696e-01,  8.3877e-01,  1.1529e+00,\n",
              "           -1.7611e+00, -1.4777e+00, -1.7557e+00,  7.6166e-02, -1.0786e+00,\n",
              "            1.4403e+00, -1.1059e-01,  5.7686e-01, -1.6917e-01, -6.4025e-02,\n",
              "            1.0384e+00,  9.0682e-01, -4.7551e-01],\n",
              "          [-8.7074e-01,  1.4474e-01,  1.9029e+00,  3.9040e-01, -3.9373e-02,\n",
              "           -8.0147e-01, -4.9554e-01, -3.6151e-01,  5.8511e-01, -1.1560e+00,\n",
              "           -1.4336e-01, -1.9474e-01, -8.5563e-02,  1.3945e+00,  5.9690e-01,\n",
              "           -4.8285e-01, -3.6610e-01, -1.3271e+00,  1.6953e+00,  2.0655e+00,\n",
              "           -2.3396e-01,  7.0732e-01,  5.8005e-01,  2.6830e-01, -2.0589e+00,\n",
              "            5.3402e-01, -5.3539e-01, -8.6366e-01],\n",
              "          [-2.3494e-02,  1.1717e+00,  3.9869e-01, -1.9872e-01, -1.1559e+00,\n",
              "           -3.1667e-01,  9.4030e-01, -1.1470e+00,  5.5880e-01,  7.9176e-01,\n",
              "           -1.8468e-01, -7.3177e-01, -8.0652e-02, -9.8006e-01,  6.0491e-02,\n",
              "           -4.8895e-01, -8.1373e-01,  8.1999e-01, -6.3317e-01,  1.2948e+00,\n",
              "            1.4628e+00, -6.2043e-01,  9.8839e-01, -4.3218e-01, -6.2322e-01,\n",
              "           -2.1625e-01, -4.8868e-01,  7.8696e-01],\n",
              "          [ 1.0759e-01, -1.0715e+00, -1.1665e-01, -1.0170e+00, -1.1980e+00,\n",
              "            4.7844e-01, -1.2295e+00, -1.3700e+00,  1.5435e+00, -3.3207e-02,\n",
              "           -4.1863e-01, -2.5560e-01, -1.2923e-01, -5.4595e-02,  4.0835e-01,\n",
              "            1.1264e+00,  1.9351e+00,  1.0077e+00,  1.0046e+00, -4.3352e-01,\n",
              "           -1.2426e+00,  1.2846e+00,  2.4377e-01,  5.3037e-01, -1.4531e-02,\n",
              "           -2.2357e+00,  1.4660e+00, -1.2191e+00],\n",
              "          [ 6.4423e-01,  3.9300e+00, -1.2442e-01,  2.9534e-01,  3.8265e-01,\n",
              "           -5.4972e-01, -9.9404e-01,  1.3459e+00,  1.9457e+00, -1.2904e+00,\n",
              "           -2.3495e+00, -2.0689e+00,  9.0942e-01, -6.9462e-01,  1.9595e+00,\n",
              "           -1.1038e+00,  5.4114e-01,  1.5390e+00,  1.0860e+00,  1.2464e+00,\n",
              "            1.1508e-01,  1.6193e+00,  4.6369e-01,  1.3007e+00,  8.7323e-01,\n",
              "            6.5127e-02,  7.7324e-01, -9.7014e-01],\n",
              "          [-8.8768e-01, -3.1832e-01, -3.3440e-01,  4.5428e-01,  4.9895e-01,\n",
              "            8.7800e-01,  3.8944e-01,  1.4625e+00,  4.7951e-01, -5.3340e-01,\n",
              "           -3.4651e-02,  6.5730e-01, -3.1122e-01, -5.6200e-01, -4.8349e-01,\n",
              "           -1.2721e+00, -1.7402e-01,  5.5412e-01, -1.8166e-01, -2.3447e-01,\n",
              "            2.9420e-01,  7.9732e-01,  1.2642e+00,  9.3549e-01,  5.4546e-01,\n",
              "           -1.5374e+00,  3.1244e-01,  7.4006e-01],\n",
              "          [ 1.4502e+00,  4.1015e+00,  1.1182e+00, -1.5668e+00, -6.9898e-01,\n",
              "            5.7439e-01,  1.2381e+00, -6.4054e-01, -7.6447e-01,  2.4084e-01,\n",
              "            1.6643e-01, -2.2318e+00,  1.3892e+00, -5.0233e-01,  1.6797e+00,\n",
              "           -1.0240e+00,  1.6859e+00, -1.2177e+00,  7.6496e-01,  1.1971e+00,\n",
              "           -7.1279e-01, -6.5576e-02,  2.2050e+00,  1.7852e+00, -1.1840e-02,\n",
              "            9.7967e-01, -1.0661e+00,  1.7720e+00],\n",
              "          [-2.7926e-01, -2.7690e-01,  7.4893e-01, -6.4346e-01, -9.5176e-01,\n",
              "            2.7152e-01,  6.7158e-01,  1.8500e+00,  1.1910e+00, -5.8986e-01,\n",
              "            9.6469e-01, -1.5094e+00,  2.2557e+00,  1.2288e+00, -4.8546e-01,\n",
              "            4.5357e-01,  1.3514e+00,  4.3393e-01, -5.1325e-01, -1.8603e-01,\n",
              "            2.7566e-01,  1.0969e-01,  3.5942e-01, -7.5374e-01,  2.2940e-01,\n",
              "           -2.5444e-01,  1.5800e+00, -2.4436e-01],\n",
              "          [-1.1991e+00, -2.5686e-02,  1.8024e+00, -1.0597e+00,  3.4028e+00,\n",
              "           -5.6867e-01, -4.7549e-01,  1.7432e+00, -2.0441e-01, -3.1641e-01,\n",
              "            1.2937e+00,  1.3453e+00,  1.9394e-01,  1.5717e+00, -3.8274e-01,\n",
              "            1.3951e+00,  3.4275e-01, -1.6045e+00, -5.8731e-01,  6.0039e-01,\n",
              "            4.3780e-01, -9.6455e-02,  3.3027e-01, -1.8752e-01, -1.4271e+00,\n",
              "            5.9255e-01, -1.1582e+00,  3.5761e-02],\n",
              "          [ 2.1601e-01, -9.1608e-01,  1.5599e+00, -3.1537e+00, -5.6110e-01,\n",
              "           -4.3030e-01, -3.3323e-01, -1.5464e+00, -1.4717e-02,  1.2251e+00,\n",
              "            1.5936e+00, -1.6315e+00, -5.6877e-02,  6.2966e-01,  2.7117e-01,\n",
              "           -6.8598e-01, -1.0918e+00,  1.6797e+00, -8.8082e-01,  5.8003e-01,\n",
              "            3.6423e-01,  8.8134e-02, -1.3069e+00, -7.0637e-01, -1.6422e-01,\n",
              "           -9.7147e-01, -1.0308e+00,  6.4728e-01],\n",
              "          [-1.9061e-01,  7.1665e-01, -2.0002e+00, -2.4097e+00,  2.1942e-01,\n",
              "           -1.6989e+00,  1.3094e+00, -1.6613e+00, -5.4607e-01, -6.3018e-01,\n",
              "           -6.3465e-01,  9.7466e-01,  2.0984e-01,  2.9890e-02,  1.7092e+00,\n",
              "           -7.2576e-01, -7.7354e-01,  5.9621e-01, -1.2504e+00,  1.1456e+00,\n",
              "            7.3934e-01,  1.2532e+00, -4.4452e-01,  8.1845e-01, -8.1802e-01,\n",
              "            3.6032e-01, -1.6146e+00, -2.4734e+00],\n",
              "          [ 3.6156e-02, -3.4222e-01, -3.8169e-01, -5.6879e-02,  8.4362e-01,\n",
              "            6.8287e-01,  3.3944e+00, -1.6688e+00,  5.1086e-01, -2.8599e-01,\n",
              "            3.3505e-01,  1.1719e+00,  1.2955e+00,  8.9086e-01, -4.8985e-01,\n",
              "           -1.1727e+00, -6.8705e-01, -2.3349e+00,  9.4041e-02, -2.0208e-01,\n",
              "           -5.9524e-02,  2.0118e+00, -3.3679e-01,  3.2598e-01,  5.3520e-01,\n",
              "            1.9733e+00, -2.0751e-01, -3.0575e-02],\n",
              "          [ 1.2673e-01,  5.5466e-03,  7.9434e-01,  4.0715e-01, -3.6090e-01,\n",
              "            1.3103e+00, -9.6505e-01,  8.8061e-01, -1.0247e-01, -6.7701e-01,\n",
              "           -4.1066e-01, -1.6186e+00,  5.0791e-01,  2.3230e+00,  2.2978e-01,\n",
              "           -5.2965e-01, -8.7331e-01,  4.2614e-03, -1.2579e+00, -1.0845e+00,\n",
              "            7.5298e-01,  3.2365e-01, -2.7501e-01,  1.3056e+00,  2.1175e-01,\n",
              "            2.7196e-01, -9.2684e-01, -2.7330e+00],\n",
              "          [-5.6417e-01, -2.7400e-01,  1.3978e-01,  5.0856e-01,  2.7710e-01,\n",
              "           -9.8125e-01,  8.8885e-01,  1.5690e+00, -8.1853e-02, -3.4940e-01,\n",
              "            2.0243e-01, -2.8838e-01,  1.4830e-01,  2.4187e+00,  1.3279e+00,\n",
              "           -2.6386e-01,  3.6447e-01,  2.5440e+00, -2.6895e+00,  2.4426e+00,\n",
              "            1.0375e-02, -9.9649e-01,  9.7850e-01, -4.4144e-01, -2.6104e-01,\n",
              "            7.9798e-01, -1.1071e+00,  2.3306e+00],\n",
              "          [-7.6502e-01, -4.7497e-01, -4.9526e-01, -1.9836e-01,  2.2149e+00,\n",
              "           -1.3669e-01, -1.0182e+00,  1.7841e-01, -5.1359e-01, -5.6443e-01,\n",
              "           -9.1837e-01, -7.4956e-01, -9.4933e-02,  1.1009e+00,  1.3105e+00,\n",
              "           -2.9285e-01, -7.8834e-01, -1.6952e-01, -2.1749e+00,  7.2025e-01,\n",
              "            2.8545e-01,  2.2903e-01,  1.2833e+00, -1.3792e+00,  5.4076e-01,\n",
              "           -9.4781e-01,  2.0214e-01, -3.5075e-01],\n",
              "          [ 5.4501e-01,  1.5412e+00,  6.0024e-01, -3.3802e-01,  4.0466e-01,\n",
              "            8.9313e-01, -1.4541e+00,  1.1875e+00, -2.9952e-01,  2.2963e+00,\n",
              "            3.3055e-01,  2.1748e+00, -1.2460e+00,  2.4966e+00, -7.0688e-01,\n",
              "            1.1504e+00, -5.4977e-01,  8.1552e-01,  2.0005e+00, -4.3935e-01,\n",
              "           -4.3190e-01, -4.7293e-01,  3.2564e-01, -9.7362e-01,  7.9789e-01,\n",
              "           -5.7330e-01,  2.0605e-01,  2.1374e-01],\n",
              "          [ 9.5440e-01,  7.3306e-01, -1.4552e+00, -2.0458e+00, -1.7707e-01,\n",
              "            6.2405e-01, -1.6889e+00,  8.1758e-01, -3.8960e-01,  1.2776e+00,\n",
              "            5.1468e-01,  3.4852e-01, -1.0379e+00, -9.5869e-01,  9.1817e-01,\n",
              "            4.8880e-01,  9.8393e-01,  9.9614e-01, -1.1658e+00, -5.8537e-01,\n",
              "           -1.8619e-01, -1.2374e+00,  1.1839e+00, -1.9545e-01, -1.3366e+00,\n",
              "            1.0511e+00, -1.0269e+00, -2.8750e-01],\n",
              "          [ 1.8480e+00, -2.3950e+00,  4.0770e-01, -1.6989e-01,  5.8418e-01,\n",
              "            1.0504e+00,  1.2856e+00, -1.6165e+00, -7.6896e-01, -1.2205e+00,\n",
              "            5.7313e-01,  6.9920e-01,  2.5106e-01,  2.7845e-01, -9.4634e-02,\n",
              "            1.6104e+00, -1.2166e-01, -1.3941e+00, -9.0479e-01, -3.4670e-01,\n",
              "            7.0494e-01,  3.0545e-02, -8.5424e-01,  5.3882e-01, -5.2649e-01,\n",
              "           -1.3320e+00,  1.5451e+00,  4.0863e-01],\n",
              "          [-2.0546e+00,  5.2591e-01,  5.9946e-01, -4.0782e-01,  4.5302e-01,\n",
              "           -3.9179e-01,  2.1403e+00, -2.0620e-01, -9.8389e-02,  4.8547e-01,\n",
              "            7.0757e-01,  4.3065e-02, -4.3944e-01, -6.7611e-01,  1.7389e+00,\n",
              "           -9.4229e-01, -1.0646e+00, -2.2971e-01, -1.2564e+00,  5.5701e-01,\n",
              "            1.5761e-01,  1.0271e+00,  1.2293e+00, -1.2231e-03, -1.8095e+00,\n",
              "            6.9256e-01,  1.1982e+00,  1.3167e+00],\n",
              "          [-3.4832e-01,  1.2075e+00, -6.4783e-01,  5.2652e-01, -9.5079e-01,\n",
              "           -2.1456e+00,  3.8271e-01, -4.0975e-01, -7.3860e-01,  1.6553e+00,\n",
              "            5.2037e-01, -2.3262e-01,  4.9742e-01,  2.6852e-01,  1.4769e+00,\n",
              "            3.5480e-01,  1.6247e+00,  5.9342e-01, -1.7254e+00, -6.2202e-01,\n",
              "           -6.2494e-03,  8.9520e-01, -7.6999e-03,  4.5172e-02,  5.7934e-01,\n",
              "           -1.5825e+00, -5.8779e-01, -1.1398e-01]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqaKVvubTlYv",
        "outputId": "18519cb7-6994-4593-9447-cf65e0253130"
      },
      "source": [
        "labels = torch.rand(1, 2)\n",
        "labels"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2231, 0.2903]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAfIdDipTp8l"
      },
      "source": [
        "model = TheModelClass()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmUcdvJlTxo5",
        "outputId": "bdbaa28b-c021-4dbd-f031-6ebc4a9006ef"
      },
      "source": [
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "  print(param_tensor, \"\\t\", model.state_dict()[param_tensor])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model's state_dict:\n",
            "conv1.weight \t tensor([[[[-9.7462e-02, -3.2472e-01,  1.7323e-02],\n",
            "          [ 5.8953e-02, -2.8221e-04,  1.0764e-01],\n",
            "          [ 3.1628e-01,  8.8628e-02, -1.2202e-01]]]])\n",
            "conv2.weight \t tensor([[[[-0.1372, -0.2133, -0.2311],\n",
            "          [-0.0537, -0.0590,  0.1483],\n",
            "          [-0.1425,  0.2657, -0.2339]]]])\n",
            "conv3.weight \t tensor([[[[ 0.0009,  0.2996,  0.3315],\n",
            "          [-0.1931,  0.0594,  0.0394],\n",
            "          [-0.1563, -0.1152,  0.0903]]]])\n",
            "fc1.weight \t tensor([[-0.2318,  0.0550,  0.1442, -0.1314,  0.2769, -0.0219,  0.1512,  0.3301,\n",
            "         -0.1019],\n",
            "        [ 0.1811, -0.0953, -0.0487, -0.0565, -0.0021, -0.1259,  0.0781,  0.0126,\n",
            "          0.2113]])\n",
            "fc1.bias \t tensor([-0.0675,  0.0334])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPPDaAdvT5Cn",
        "outputId": "220784ea-e949-412c-dc3f-678307138136"
      },
      "source": [
        "print(\"Optimizer's state_dict:\")\n",
        "for var_name in optimizer.state_dict():\n",
        "    print(var_name, \"\\t\", optimizer.state_dict())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer's state_dict:\n",
            "state \t {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4]}]}\n",
            "param_groups \t {'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4]}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D04K5eLaXsbg"
      },
      "source": [
        "preds = model(x)\n",
        "loss = (preds - labels).sum()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}